---
title: "Final Project: Structure & Deliverables"
author: "Zuhayr Baqar, Dan Ngyuyen, Rachel Roggenkemper, Annie Zell (Group 5)"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(readxl)
library(kableExtra)
library(grid)
library(extrafont)
library(broom)
```

```{r}
US_schools <- read_excel("US_schools_data.xlsx")
```



# The Data
The data for this project were pulled from the Urban Institute’s API. The master dataset brings together multiple facets of U.S. education data into one convenient CSV, including data related to student’s race and sex.

These data can be downloaded from Canvas, under US_schools_data.csv.

A more thorough documentation of the variables in the dataset and how they are coded can be found: in this Kaggle project



# Data Cleaning
It is often said that 80-90% of what a “data scientist” does is clean and organize data, in preparation for an analysis. I have certainly found this to be true, and you will see why!

As is typical for large collated datasets (datasets that are merged together), these data are in wide format, meaning there are multiple variables spread across the columns. For example, grade, race, and exam are spread across different columns, using prefixes to describe the level of the variable (e.g., G04_WH_A_READING is the grade 4 average reading score for White students).

Hint: The ends_with() function is quite helpful here!


## Data Narrowing
For this analysis, we are interested in the school expenditure variables (TOTAL_EXPENDITURE, INSTRUCTION_EXPENDITURE, SUPPORT_SERVICES_EXPENDITURE, OTHER_EXPENDITURE, CAPITAL_OUTLAY_EXPENDITURE), and the testing variables (anything ending in READING or MATHEMATICS). Downsize the dataset to only include these variables, as well as the key column identifying the state / year.


## Separating Key Column
The PRIMARY_KEY column contains information for both the state and the year of the observation. Separate this columns into two columns.

Hint: The word() function is quite helpful here!

```{r}
#Split the year from the state
year_state<- US_schools$PRIMARY_KEY
x <- str_replace_all(year_state, "_", " ")
x <- str_split_fixed(x, " ", n = 2)
split_year_state <- data.frame(x)
split_year_state<- rename(split_year_state, YEAR = X1, STATE = X2)
  
#select columns and merge split_year_state columns
schools_clean <- US_schools %>%
  cbind(split_year_state) %>%
  select(YEAR, STATE,TOTAL_EXPENDITURE, INSTRUCTION_EXPENDITURE, SUPPORT_SERVICES_EXPENDITURE, OTHER_EXPENDITURE, CAPITAL_OUTLAY_EXPENDITURE, ends_with(c("READING", "MATHEMATICS")) )
```


## Pivoting Longer
The grade (04, 08), race (AM, AS, BL, HI, HP, TR, WH), sex (A, F, M), and test (READING, MATHEMATICS) are spread across the columns. We need to pivot these variables to be included in one column each (e.g., grade, race, sex, test).

Hint: the names_sep argument in pivot_longer() is very helpful here!

```{r}
schools_clean <- schools_clean %>%
  pivot_longer(8:47, names_to = c("GRADE", "RACE", "SEX", "TEST"), names_sep ="_", values_to = "TEST_SCORES")
```


## Regional Classification
Similar to the midterm exam, create a regional grouping for the states. As this will be presented in a written report, be mindful about how you classify the regions. You will need to convince me why you believe these different regions would have different relationships between school expenditures and student test scores.

```{r, message = FALSE, warning = FALSE, include = FALSE}
# creating a data frame called regions which contains each State included in the min_wage dataset and its corresponding region 
regions <- 
  data.frame(
    STATE = toupper(c("MAINE", "MASSACHUSETTS", "Rhode Island", "Connecticut", "New Hampshire", "Vermont", "New York", "Pennsylvania", "New Jersey", "Delaware", "Maryland", "West Virginia", "Virginia", "Kentucky", "Tennessee", "North Carolina", "South Carolina", "Georgia", "Alabama", "Mississippi", "Arkansas", "Louisiana", "Florida", "Ohio", "Indiana", "Michigan", "Illinois", "Missouri", "Wisconsin", "Minnesota", "Iowa", "Kansas", "Nebraska", "South Dakota", "North Dakota", "Texas", "Oklahoma", "New Mexico", "Arizona", "Colorado", "Wyoming", "Montana", "Idaho", "Washington", "Oregon", "Utah", "Nevada", "California", "Alaska", "Hawaii", "District of Columbia", "Federal (FLSA)", "U.S. Virgin Islands", "Guam", "Puerto Rico")), 
    Region = c("Northeast", "Northeast", "Northeast", "Northeast", "Northeast", "Northeast", "Northeast", "Northeast", "Northeast", "Northeast", "Northeast", "Southeast", "Southeast", "Southeast", "Southeast", "Southeast", "Southeast", "Southeast", "Southeast", "Southeast", "Southeast", "Southeast", "Southeast", "Midwest", "Midwest", "Midwest", "Midwest", "Midwest", "Midwest", "Midwest", "Midwest", "Midwest", "Midwest", "Midwest", "Midwest", "Southwest", "Southwest", "Southwest", "Southwest", "West", "West", "West", "West", "West", "West", "West", "West", "West", "West", "West", "Southeast", "Other", "Other", "Other", "Other"))
```

```{r}
schools_clean <- 
  schools_clean %>%
  left_join(regions, by = "STATE") %>%
  filter(STATE != "DODEA", STATE != "NATIONAL")
```


## Additional Cleaning
Feel free to clean up the values of these variables! Keep in mind that these are the values that will print to the visualizations you make! For example, maybe you would prefer for the grade variable to only have levels "4" and "8", or maybe you’d prefer test to have levels "Mathematics" and "Reading". I would highly recommend renaming the “A” level of sex to say "all"!

You should also consider what variables you want to be factors, and if there are specific orderings that you would like for them to be displayed in for your visualizations!

```{r}

sex_fct <- schools_clean$SEX

sex_fct <- fct_recode(sex_fct, All = "A", Male = "M", Female = "F")

schools_clean <- schools_clean %>% mutate(SEX = sex_fct)

```

```{r}
schools_clean <- schools_clean %>% mutate(GRADE = str_extract(GRADE, "[1-9]"))
```

```{r, message = FALSE, warning = FALSE}
schools_clean$SEX[schools_clean$SEX == "A"] = "All"
schools_clean$SEX[schools_clean$SEX == "F"] = "Female"
schools_clean$SEX[schools_clean$SEX == "M"] = "Male"
schools_clean$RACE[schools_clean$RACE == "AM"] = "American Indian or Alaska Native"
schools_clean$RACE[schools_clean$RACE == "AS"] = "Asian"
schools_clean$RACE[schools_clean$RACE == "HI"] = "Hispanic/Latino"
schools_clean$RACE[schools_clean$RACE == "BL"] = "Black or African American"
schools_clean$RACE[schools_clean$RACE == "WH"] = "White"
schools_clean$RACE[schools_clean$RACE == "HP"] = "Hawaiian Native/Pacific Islander"
schools_clean$RACE[schools_clean$RACE == "TR"] = "Two or More Races"
schools_clean$RACE[schools_clean$RACE == "A"] = "All"
schools_clean$GRADE[schools_clean$GRADE == "G04"] = 4
schools_clean$GRADE[schools_clean$GRADE == "G08"] = 8
```



# Data Visualization
Create at least three different visualizations exploring the following:

##### The relationship between instructional expenditures and testing scores, and how this differs by regions

```{r}
plot1 <- schools_clean %>% 
  ggplot(aes(x = INSTRUCTION_EXPENDITURE, y = TEST_SCORES)) + 
  geom_jitter(cex = .8, aes(color = RACE), alpha = 0.5) + 
  scale_fill_brewer() +
  geom_smooth(color = "black",fill = "darkgrey", method = "lm", se = FALSE) +
  facet_wrap(~Region, nrow =  3)+
  labs(x = "Instruction Expenditure", y = "Test Scores", title = "How School Expenditures Impacts Test Scores") +
  ggtitle("How School Expenditures Impacts Test Scores") +
  xlab("Instruction Expenditure") + ylab("Test Scores") +
  theme(text=element_text(size=10, family="Times"), legend.position = "right") 

plot1 + scale_colour_brewer(palette = "Set2") 
```

```{r}
schools_sample <- schools_clean %>%
  sample_n(20000, na.rm = F) %>%
  filter(SEX != "All")

plot2 <- schools_sample %>% 
  ggplot(aes(x = INSTRUCTION_EXPENDITURE, y = TEST_SCORES)) + 
  geom_jitter(cex = .8, aes(color = SEX)) + 
  scale_fill_brewer() +
  geom_smooth(color = "black",fill = "darkgrey", method = "lm", se = FALSE) +
  facet_wrap(~Region, nrow =  3)+
  labs(x = "Instruction Expenditure", y = "Test Scores", title = "How School Expenditures Impacts Test Scores") +
  ggtitle("How School Expenditures Impacts Test Scores") +
  xlab("Instruction Expenditure") + ylab("Test Scores") +
  theme(text=element_text(size=10, family="Times"), legend.position = "right") 

plot2 + scale_colour_brewer(palette = "Set2") 
```


##### The distribution of mathematics and reading test scores:

```{r}
cdPalette <- c("#F1c2bc", "#Ffd5b9", "#Ebffb9", "#B9ffd6", "#B9fff8", "#B9bcff", "#Ffb9fe", "#C6bcbc")

loadfonts(device = "win")

schools_clean %>%
  ggplot(aes(x = TEST_SCORES, fill = RACE)) + 
  geom_boxplot() + 
  facet_wrap(TEST~SEX) + 
  theme(panel.spacing = unit(0.1, "lines")) + 
  theme(panel.grid.minor = element_line(colour = "white", size = 1)) +
  labs(x = "Test Scores", title = "Distribution of Mathematics and Reading Test Scores by Sex and Race", y = "") +
  annotate("text", x = 150, y = -0.33, label = "All", color = "black", size = 3) +
  scale_fill_manual(values = cdPalette) +
  theme(text = element_text(size = 12,  family = "serif")) +
  theme(axis.ticks = element_blank(), axis.text.y = element_blank())
```

```{r}
schools_clean %>%
  ggplot(aes(x= SEX, y = TEST_SCORES, color = SEX)) + 
  geom_jitter(alpha = 0.2) +
  geom_boxplot(alpha = 0.8) + 
  labs(y= "Test Score", title = "Distribution of Test Scores by Sex") + 
  scale_colour_manual(values = c("Dark Green", "Pink", "Light Blue")) + 
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    panel.grid.major = element_blank(),
    axis.title.x = element_blank(),
    legend.position = "none"
    ) +
  annotate("text", x = 3, y = 177, label = "Male") + 
  annotate("text", x = 2, y = 180, label = "Female") + 
  annotate("text", x = 1, y = 170, label = "All") + 
  facet_wrap(~TEST)
```


##### How school instructional expenditures and test scores have changed over time, and how this differs by region

```{r}
schools_clean %>%
  ggplot(aes(x = YEAR, y = TEST_SCORES)) +
  geom_boxplot() +
  facet_wrap(~Region) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  scale_x_discrete(guide = guide_axis(n.dodge=2))
```

Each of these visualizations should also investigate how these relationships differ based on student race and sex.



# Linear Regression
Fit two simple linear regression models, (1) investigating the relationship between instructional expenditures and mathematics test scores, and (2) investigating the relationship between instructional expenditures and reading test scores.

```{r}
expend_math <- schools_clean %>% filter(TEST == "MATHEMATICS") %>% lm(TEST_SCORES ~ INSTRUCTION_EXPENDITURE, data = .)

expend_reading <- schools_clean %>% filter(TEST == "READING") %>% lm(TEST_SCORES ~ INSTRUCTION_EXPENDITURE, data = .)
```


## Model Comparison
For which test does instructional expenditures account for a larger proportion of the variability? How substantial is the difference?


##### Relationship between instructional expenditures and *mathematics* test scores 
```{r MathReg}
summary(expend_math)
```


##### Relationship between instructional expenditures and *reading* test scores 

```{r ReadingReg}
summary(expend_reading)
```

From the two models that we created, the math model resulted in instruction expenditure accounting for 0.426% of the variability in test scores while the reading model resulted in instruction expenditure accounting for 0.036% of the variability in test scores 


## Multiple Linear Regression

### Both Tests
Rather than having separate models, one for reading and one for mathematics, we can instead fit one regression model that includes test as an explanatory variable.

```{r MLR}
schools_clean  %>% 
  lm(
    TEST_SCORES ~ INSTRUCTION_EXPENDITURE + TEST, data = .
    ) %>% 
  summary()
```


Does this model account for a larger proportion of variability in test scores?


### Additional Variables
Alright, now that we’ve got a “good” starting model, we can start to add variables. It is clear that the relationship between instructional expenditures and test scores changes over time. So, let’s make a time-series model to account for this.

Include year as a second explanatory variable in your model. How much additional variability in test scores were you able to explain by including year?

```{r}
schools_clean  %>% mutate(YEAR = as.numeric(YEAR)) %>% 
  lm(TEST_SCORES ~ INSTRUCTION_EXPENDITURE + TEST + YEAR  , data = .) %>%
  summary()
```


## Adjusting for Complexity
There is a trade off between model “complexity” and an increase in a model’s R2. Unfortunately, even if a variable doesn’t add much to the model, the R2 for that model will still increase. So, we need a different measure that can account for whether the variable(s) explain components of the variability in test scores that weren’t accounted for by other variables.

This is where adjusted R2 comes in. By “adjusting” the R2, we are essentially making a penalty for whether the extra variable added something “new” to the model.

Include additional variables in your regression and see how much variability in test scores your model can account for. Use adjusted R2 to decide on what final model your group believes is the “best.”

```{r}
final_model <- schools_clean  %>% 
  mutate(YEAR = as.numeric(YEAR)) %>% 
  lm(
    TEST_SCORES ~ INSTRUCTION_EXPENDITURE + TEST + YEAR + GRADE + Region , data = .
    )
summary(final_model)
```


With your final model, make a visualization that explores the relationships accounted for in your model.

```{r}
# creating a dataset that removes na values to match the number of observations with the regressions.
schools_model <- schools_clean %>% 
  filter(!is.na(TEST_SCORES)) %>% 
  filter(!is.na(INSTRUCTION_EXPENDITURE)) %>% 
  filter(!is.na(YEAR))
```


With your chosen model, generate predictions using the predict() function. Then, add random errors to the predictions, using the residual standard error estimated from the linear regression model (acquired with sigma()).

```{r}
# saving the predicted values and the standard deviation
model_pred <- predict(final_model)
model_sig <- sigma(final_model)
```

Tip: Measure the R-squared between expected vs observed values, SSE, and RMSE


```{r}
noise <- function(x, mean = 0, sd){
  n <- length(x)
  new_data <- x + rnorm(n, mean, sd)
  return(new_data)
}
```

```{r}
schools_model <- schools_model %>% 
  mutate(
    predicted = noise(model_pred, sd = model_sig)
                   )
```


Now, compare these simulated observations to the observed data. Generate the same plot of the relationships modeled by the linear regression, for the simulated data (that you made at the end of Part One).
Plot the visualization of the observed data and the simulated data side-by-side. Discuss how the simulated data are similar and / or different to the observed data.

```{r}

schools_model %>% 
  ggplot(aes(INSTRUCTION_EXPENDITURE, TEST_SCORES, color = TEST, linetype = GRADE)) + 
  geom_jitter(alpha = 0.4) +
  geom_smooth(method = "lm") + 
  facet_wrap(~YEAR) + 
  labs(x = "Instruction Expenditure", y = "Test Scores", title = "Regression with Observed Values", color = "Test", linetype = "Grade" )

schools_model %>% 
  ggplot(aes(INSTRUCTION_EXPENDITURE, predicted, color = TEST, linetype = GRADE)) + 
  geom_jitter(alpha = 0.4) +
  geom_smooth(method = "lm") + 
  facet_wrap(~YEAR) + 
  labs(x = "Instruction Expenditure", y = "Predicted Test Scores", title = "Regression With Predicted Values", color = "Test", linetype = "Grade" )
```


```{r}
nsims <- 1000

sims <- map_dfc(1:nsims,
                ~tibble(sim = noise(model_pred, sd = model_sig))) 
sims <- schools_model %>% 
  select(TEST_SCORES) %>% 
  bind_cols(sims)
```
```{r}
obs_vs_sim <- function(df){
  lm(penguins$bill_length_mm ~ x)
}

sim_r_sq <- sims %>% 
  map( ~lm(TEST_SCORES ~ .x, data = sims)) %>% 
  map(glance) %>% 
  map_dbl(~.$r.squared) %>% data.frame()

sim_r_sq <- sim_r_sq[names(sim_r_sq) != "bill_length_mm"]
```

```{r}
tibble(sims = sim_r_sq) %>% 
  ggplot(aes(x = sims)) + 
  geom_histogram(binwidth = 0.0105)
```


```{r}
sim_r_sq %>% ggplot(aes(sim_r_sq)) + geom_density() + xlim(0.7, 0.73)
```




Citations: 
https://datavizpyr.com/how-to-dodge-overlapping-text-on-x-axis-labels-in-ggplot2/
https://stackoverflow.com/questions/12692382/ggplot2-facet-margin
https://stackoverflow.com/questions/18081746/controlling-both-the-major-and-minor-grid-lines-on-the-y-axis
https://stackoverflow.com/questions/34522732/changing-fonts-in-ggplot2
https://statisticsglobe.com/remove-axis-labels-and-ticks-of-ggplot2-plot-in-r

